@inproceedings{ort2018autonomous,
	title={Autonomous vehicle navigation in rural environments without detailed prior maps},
	author={Ort, Teddy and Paull, Liam and Rus, Daniela},
	booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
	pages={2040--2047},
	year={2018},
	organization={IEEE}
}

@article{scholz2006approaches,
	title={Approaches to analyse and interpret biological profile data},
	author={Scholz, Matthias},
	year={2006}
}

@article{franccois2018introduction,
	title={An introduction to deep reinforcement learning},
	author={Fran{\c{c}}ois-Lavet, Vincent and Henderson, Peter and Islam, Riashat and Bellemare, Marc G and Pineau, Joelle and others},
	journal={Foundations and Trends{\textregistered} in Machine Learning},
	volume={11},
	number={3-4},
	pages={219--354},
	year={2018},
	publisher={Now Publishers, Inc.}
}


@inproceedings{gu2017deep,
	title={Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates},
	author={Gu, Shixiang and Holly, Ethan and Lillicrap, Timothy and Levine, Sergey},
	booktitle={2017 IEEE international conference on robotics and automation (ICRA)},
	pages={3389--3396},
	year={2017},
	organization={IEEE}
}


@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@article{watkins1989learning,
	title={Learning from delayed rewards},
	author={Watkins, Christopher John Cornish Hellaby},
	year={1989},
	publisher={King's College, Cambridge}
}


@book{lapan2018deep,
	title={Deep Reinforcement Learning Hands-On: Apply modern RL methods, with deep Q-networks, value iteration, policy gradients, TRPO, AlphaGo Zero and more},
	author={Lapan, Maxim},
	year={2018},
	publisher={Packt Publishing Ltd}
}


@online{openai2018spinningup,
	author = {OpenAI},
	title = {{OpenAI} Spinning Up},
	year = {2019},
	note = {\href{https://web.archive.org/web/20190729131615/https://spinningup.openai.com/en/latest/}{https://spinningup.openai.com/}},
	urldate = {2019-07-29}
}

@online{cozmo2019SDK,
	author = {Anki},
	title = {Github repository of {Cozmo SDK} written in Python},
	year = {2019},
	note = {\href{https://github.com/anki/cozmo-python-sdk}{https://github.com/anki/cozmo-python-sdk}}
}



@article{silver2016mastering,
	title={Mastering the game of Go with deep neural networks and tree search},
	author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
	journal={nature},
	volume={529},
	number={7587},
	pages={484},
	year={2016},
	publisher={Nature Publishing Group}
}

@article{silver2017mastering,
	title={Mastering chess and shogi by self-play with a general reinforcement learning algorithm},
	author={Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and others},
	journal={arXiv preprint arXiv:1712.01815},
	year={2017}
}


@article{mnih2013playing,
	title={Playing atari with deep reinforcement learning},
	author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
	journal={arXiv preprint arXiv:1312.5602},
	year={2013}
}


@unpublished{silver2015lectures,
	Author = {David Silver},
	Institution = {University College London},
	Year = {2015},
	Title = {University College London Course on Reinforcement Learning},
	note = {\href{https://web.archive.org/web/20190731043016/http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html}{http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html}}
}

@article{kendall2018learning,
	title={Learning to Drive in a Day},
	author={Kendall, Alex and Hawke, Jeffrey and Janz, David and Mazur, Przemyslaw and Reda, Daniele and Allen, John-Mark and Lam, Vinh-Dieu and Bewley, Alex and Shah, Amar},
	journal={arXiv preprint arXiv:1807.00412},
	year={2018}
}

@article{lillicrap2015continuous,
	title={Continuous control with deep reinforcement learning},
	author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
	journal={arXiv preprint arXiv:1509.02971},
	year={2015}
}
@article{brockman2016openai,
	title={Openai gym, 2016},
	author={Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
	journal={arXiv preprint arXiv:1606.01540},
	year={2016}
}

@article{mnih2015human,
	title={Human-level control through deep reinforcement learning},
	author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
	journal={Nature},
	volume={518},
	number={7540},
	pages={529},
	year={2015},
	publisher={Nature Publishing Group}
}

@article{schulman2017proximal,
	title={Proximal policy optimization algorithms},
	author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
	journal={arXiv preprint arXiv:1707.06347},
	year={2017}
}


@inproceedings{mnih2016asynchronous,
	title={Asynchronous methods for deep reinforcement learning},
	author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
	booktitle={International conference on machine learning},
	pages={1928--1937},
	year={2016}
}


@article{schaul2015prioritized,
	title={Prioritized experience replay},
	author={Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
	journal={arXiv preprint arXiv:1511.05952},
	year={2015}
}

@article{uhlenbeck1930theory,
	title={On the theory of the Brownian motion},
	author={Uhlenbeck, George E and Ornstein, Leonard S},
	journal={Physical review},
	volume={36},
	number={5},
	pages={823},
	year={1930},
	publisher={APS}
}

@article{erhan2009visualizing,
	title={Visualizing higher-layer features of a deep network},
	author={Erhan, Dumitru and Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
	journal={University of Montreal},
	volume={1341},
	number={3},
	pages={1},
	year={2009}
}

@article{rumelhart1988learning,
	title={Learning representations by back-propagating errors},
	author={Rumelhart, David E and Hinton, Geoffrey E and Williams, Ronald J and others},
	journal={Cognitive modeling},
	volume={5},
	number={3},
	pages={1},
	year={1988}
}


@article{lecun1995convolutional,
	title={Convolutional networks for images, speech, and time series},
	author={LeCun, Yann and Bengio, Yoshua and others},
	journal={The handbook of brain theory and neural networks},
	volume={3361},
	number={10},
	pages={1995},
	year={1995}
}

@article{kingma2014adam,
	title={Adam: A method for stochastic optimization},
	author={Kingma, Diederik P and Ba, Jimmy},
	journal={arXiv preprint arXiv:1412.6980},
	year={2014}
}
@article{duchi2011adaptive,
	title={Adaptive subgradient methods for online learning and stochastic optimization},
	author={Duchi, John and Hazan, Elad and Singer, Yoram},
	journal={Journal of Machine Learning Research},
	volume={12},
	number={Jul},
	pages={2121--2159},
	year={2011}
}

@book{bellman2015applied,
	title={Applied dynamic programming},
	author={Bellman, Richard E and Dreyfus, Stuart E},
	volume={2050},
	year={2015},
	publisher={Princeton university press}
}

@article{lin1992self,
	title={Self-improving reactive agents based on reinforcement learning, planning and teaching},
	author={Lin, Long-Ji},
	journal={Machine learning},
	volume={8},
	number={3-4},
	pages={293--321},
	year={1992},
	publisher={Springer}
}

@article{tieleman2012lecture,
	title={Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude},
	author={Tieleman, Tijmen and Hinton, Geoffrey},
	journal={COURSERA: Neural networks for machine learning},
	volume={4},
	number={2},
	pages={26--31},
	year={2012}
}

@inproceedings{hessel2018rainbow,
	title={Rainbow: Combining improvements in deep reinforcement learning},
	author={Hessel, Matteo and Modayil, Joseph and Van Hasselt, Hado and Schaul, Tom and Ostrovski, Georg and Dabney, Will and Horgan, Dan and Piot, Bilal and Azar, Mohammad and Silver, David},
	booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
	year={2018}
}

@inproceedings{van2016deep,
	title={Deep reinforcement learning with double q-learning},
	author={Van Hasselt, Hado and Guez, Arthur and Silver, David},
	booktitle={Thirtieth AAAI conference on artificial intelligence},
	year={2016}
}

@incollection{hasselt2010double,
	title = {Double Q-learning},
	author = {Hado V. Hasselt},
	booktitle = {Advances in Neural Information Processing Systems 23},
	editor = {J. D. Lafferty and C. K. I. Williams and J. Shawe-Taylor and R. S. Zemel and A. Culotta},
	pages = {2613--2621},
	year = {2010},
	publisher = {Curran Associates, Inc.},
	url = {http://papers.nips.cc/paper/3964-double-q-learning.pdf}
}

@article{wang2015dueling,
	title={Dueling network architectures for deep reinforcement learning},
	author={Wang, Ziyu and Schaul, Tom and Hessel, Matteo and Van Hasselt, Hado and Lanctot, Marc and De Freitas, Nando},
	journal={arXiv preprint arXiv:1511.06581},
	year={2015}
}

@inproceedings{konda2000actor,
	title={Actor-critic algorithms},
	author={Konda, Vijay R and Tsitsiklis, John N},
	booktitle={Advances in neural information processing systems},
	pages={1008--1014},
	year={2000}
}

@online{stanford2019cs231n,
	author = {{Stanford University}},
	title = {{CS231n}: Convolutional Neural Networks for Visual Recognition},
	year = {2019},
	note = {\href{http://cs231n.github.io/}{http://cs231n.github.io/}},
	urldate = {2019-07-29}
}

@book{shalev2014understanding,
	title={Understanding machine learning: From theory to algorithms},
	author={Shalev-Shwartz, Shai and Ben-David, Shai},
	year={2014},
	publisher={Cambridge university press}
}

@article{lecun2015deep,
	title={Deep learning},
	author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
	journal={nature},
	volume={521},
	number={7553},
	pages={436},
	year={2015},
	publisher={Nature Publishing Group}
}

@book{bishop2006pattern,
	title={Pattern recognition and machine learning},
	author={Bishop, Christopher M},
	year={2006},
	publisher={springer}
}

@article{ioffe2015batch,
	title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},
	author={Ioffe, Sergey and Szegedy, Christian},
	journal={arXiv preprint arXiv:1502.03167},
	year={2015}
}

@article{lecun1998gradient,
	title={Gradient-based learning applied to document recognition},
	author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick and others},
	journal={Proceedings of the IEEE},
	volume={86},
	number={11},
	pages={2278--2324},
	year={1998},
	publisher={Taipei, Taiwan}
}

@inproceedings{silver2014deterministic,
	title={Deterministic policy gradient algorithms},
	author={Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
	year={2014}
}

@article{haarnoja2018soft,
	title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
	author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
	journal={arXiv preprint arXiv:1801.01290},
	year={2018}
}

@article{haarnoja2018alg,
	title={Soft actor-critic algorithms and applications},
	author={Haarnoja, Tuomas and Zhou, Aurick and Hartikainen, Kristian and Tucker, George and Ha, Sehoon and Tan, Jie and Kumar, Vikash and Zhu, Henry and Gupta, Abhishek and Abbeel, Pieter and others},
	journal={arXiv preprint arXiv:1812.05905},
	year={2018}
}

@article{fujimoto2018addressing,
	title={Addressing function approximation error in actor-critic methods},
	author={Fujimoto, Scott and van Hoof, Herke and Meger, David},
	journal={arXiv preprint arXiv:1802.09477},
	year={2018}
}

@inproceedings{duan2016benchmarking,
	title={Benchmarking deep reinforcement learning for continuous control},
	author={Duan, Yan and Chen, Xi and Houthooft, Rein and Schulman, John and Abbeel, Pieter},
	booktitle={International Conference on Machine Learning},
	pages={1329--1338},
	year={2016}
}

@inproceedings{henderson2018deep,
	title={Deep reinforcement learning that matters},
	author={Henderson, Peter and Islam, Riashat and Bachman, Philip and Pineau, Joelle and Precup, Doina and Meger, David},
	booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
	year={2018}
}

@inproceedings{haarnoja2017reinforcement,
	title={Reinforcement learning with deep energy-based policies},
	author={Haarnoja, Tuomas and Tang, Haoran and Abbeel, Pieter and Levine, Sergey},
	booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
	pages={1352--1361},
	year={2017},
	organization={JMLR. org}
}
@article{ziebart2008maximum,
	title={Maximum entropy inverse reinforcement learning},
	author={Ziebart, Brian D and Maas, Andrew and Bagnell, J Andrew and Dey, Anind K},
	year={2008},
	publisher={figshare}
}

@inproceedings{toussaint2009robot,
	title={Robot trajectory optimization using approximate inference},
	author={Toussaint, Marc},
	booktitle={Proceedings of the 26th annual international conference on machine learning},
	pages={1049--1056},
	year={2009},
	organization={ACM}
}

@inproceedings{rawlik2013stochastic,
	title={On stochastic optimal control and reinforcement learning by approximate inference},
	author={Rawlik, Konrad and Toussaint, Marc and Vijayakumar, Sethu},
	booktitle={Twenty-Third International Joint Conference on Artificial Intelligence},
	year={2013}
}

@article{fox2015taming,
	title={Taming the noise in reinforcement learning via soft updates},
	author={Fox, Roy and Pakman, Ari and Tishby, Naftali},
	journal={arXiv preprint arXiv:1512.08562},
	year={2015}
}

@techreport{kullback1959information,
	title={Information theory and statistics},
	author={Kullback, Solomon},
	year={1959}
}

@article{kullback1951information,
	title={On information and sufficiency},
	author={Kullback, Solomon and Leibler, Richard A},
	journal={The annals of mathematical statistics},
	volume={22},
	number={1},
	pages={79--86},
	year={1951},
	publisher={JSTOR}
}

@inproceedings{kendall2019learning,
	title={Learning to drive in a day},
	author={Kendall, Alex and Hawke, Jeffrey and Janz, David and Mazur, Przemyslaw and Reda, Daniele and Allen, John-Mark and Lam, Vinh-Dieu and Bewley, Alex and Shah, Amar},
	booktitle={2019 International Conference on Robotics and Automation (ICRA)},
	pages={8248--8254},
	year={2019},
	organization={IEEE}
}

@online{wayve2019human,
	author = {WAYVE},
	title = {Learning to Drive like a Human},
	year = {2019},
	note = {\href{https://wayve.ai/blog/driving-like-human}{https://wayve.ai/blog/driving-like-human}},
	urldate = {2019-04-03}
}

@article{badrinarayanan2017segnet,
	title={Segnet: A deep convolutional encoder-decoder architecture for image segmentation},
	author={Badrinarayanan, Vijay and Kendall, Alex and Cipolla, Roberto},
	journal={IEEE transactions on pattern analysis and machine intelligence},
	volume={39},
	number={12},
	pages={2481--2495},
	year={2017},
	publisher={IEEE}
}

@inproceedings{deisenroth2011pilco,
	title={PILCO: A model-based and data-efficient approach to policy search},
	author={Deisenroth, Marc and Rasmussen, Carl E},
	booktitle={Proceedings of the 28th International Conference on machine learning (ICML-11)},
	pages={465--472},
	year={2011}
}


@article{rezende2014stochastic,
	title={Stochastic backpropagation and approximate inference in deep generative models},
	author={Rezende, Danilo Jimenez and Mohamed, Shakir and Wierstra, Daan},
	journal={arXiv preprint arXiv:1401.4082},
	year={2014}
}

@article{kingma2013auto,
	title={Auto-encoding variational bayes},
	author={Kingma, Diederik P and Welling, Max},
	journal={arXiv preprint arXiv:1312.6114},
	year={2013}
}

@online{openai2018dota,
	author = {OpenAI},
	title = {OpenAI Five},
	year = {2018},
	note = {\href{https://openai.com/blog/openai-five/}{https://openai.com/blog/openai-five/}},
	urldate = {2018-06-25}
}

@online{openai2019dota,
	author = {OpenAI},
	title = {How to Train Your OpenAI Five},
	year = {2019},
	note = {\href{https://openai.com/blog/how-to-train-your-openai-five/}{https://openai.com/blog/how-to-train-your-openai-five/}},
	urldate = {2019-04-15}
}

@online{bair2019soft,
	author = {Berkeley Artifical Intelligence Research},
	title = {Soft Actor Criticâ€”Deep Reinforcement Learning with Real-World Robots},
	year = {2018},
	note = {\href{https://bair.berkeley.edu/blog/2018/12/14/sac/}{https://bair.berkeley.edu/blog/2018/12/14/sac/}},
	urldate = {2018-12-14}
}
@inproceedings{bewley2019learning,
	title={Learning to drive from simulation without real world labels},
	author={Bewley, Alex and Rigley, Jessica and Liu, Yuxuan and Hawke, Jeffrey and Shen, Richard and Lam, Vinh-Dieu and Kendall, Alex},
	booktitle={2019 International Conference on Robotics and Automation (ICRA)},
	pages={4818--4824},
	year={2019},
	organization={IEEE}
}

@inproceedings{deng2009imagenet,
	title={Imagenet: A large-scale hierarchical image database},
	author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
	booktitle={2009 IEEE conference on computer vision and pattern recognition},
	pages={248--255},
	year={2009},
	organization={Ieee}
}

@online{openaigymgithub,
	author = {OpenAI},
	title = {{OpenAI} Gym},
	year = {2016},
	note = {\href{https://github.com/openai/gym}{https://github.com/openai/gym}},
	urldate = {2019-07-29}
}
@online{openaigymdocs,
	author = {OpenAI},
	title = {{OpenAI} Gym Documentation},
	year = {2016},
	note = {\href{https://gym.openai.com/docs/}{https://gym.openai.com/docs/}},
	urldate = {2019-07-29}
}

@misc{openaigymwhite,
	Author = {Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and John Schulman and Jie Tang and Wojciech Zaremba},
	Title = {OpenAI Gym},
	Year = {2016},
	Eprint = {arXiv:1606.01540},
}

@article{bellemare2013arcade,
	title={The arcade learning environment: An evaluation platform for general agents},
	author={Bellemare, Marc G and Naddaf, Yavar and Veness, Joel and Bowling, Michael},
	journal={Journal of Artificial Intelligence Research},
	volume={47},
	pages={253--279},
	year={2013}
}


@online{ingredientsRoboticsResearch,
	author =       {  Plappert, Matthias and Andrychowicz, Marcin and Ray, Alex and McGrew, Bob and  Baker, Bowen and Powell, Glenn and Schneider, Jonas and Tobin, Josh and Chociej, Maciek and Welinder, Peter and Kumar, Vikash and Zaremba, Wojciech},
	title =        {Ingredients for	Robotics Research},
	editor =       {OpenAI blog},
	month =        {February},
	year =         {2018},
	url =          {\href{https://openai.com/blog/ingredients-for-robotics-research/}},
	note =         {\href{https://openai.com/blog/ingredients-for-robotics-research/}{https://openai.com/blog/ingredients-for-robotics-research/}},
}

@online{govtech2018aut,
	author =       {{GovTech: Government Technology}},
	title =        {Autonomous Vehicles: Coming to a Road Near You },
	month =        {August},
	year =         {2018},
	url =          {https://www.govtech.com/transportation/Autonomous-Vehicles-Coming-to-a-Road-Near-You.html}
}


@online{chara2018wild,
	author  = {Mohamad Charafeddine},
	title   = {{Reinforcement Learning in the Wild and Lessons Learned}},
	year    = {2018},
	url    = {https://link.medium.com/SRUZ24Itx4},
	urldate = {2018-10-26}
}

@misc{pavone2019veicoli,
	author = {Marco Pavone},
	title = {Veicoli a guida autonoma: a che punto siamo e cosa ci aspetta?},
	institution = {Politecnico di Torino},
	month = {November},
	year = {2019},
	note = {Festival della Tecnologia Conference}
}

